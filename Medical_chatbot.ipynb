{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMpvr0jsh/StWxyu+nAkx12",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EbubeTheGoat/Asthma_medical_chatbot/blob/main/Medical_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRk6iRb43ESN"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('pharmacy.db')\n",
        "print(\"Opened database successfully\")"
      ],
      "metadata": {
        "id": "TCs6Vj936E4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn.execute(\"\"\"\n",
        "CREATE TABLE disease(\n",
        "  id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "  name TEXT,\n",
        "  symptoms TEXT,\n",
        "  treatment TEXT\n",
        ")\n",
        " \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "_qlimpOi6RaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn.commit()"
      ],
      "metadata": {
        "id": "E8RWeJI87ykg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn.execute(\"\"\"\n",
        "INSERT INTO disease(name,symptoms,treatment)\n",
        "VALUES(?,?,?)\n",
        "\"\"\",(\n",
        "    \"Asthma\",\n",
        "    \"Shortness of breath,chest tightness,wheezing,coughing(especially at night)\",\n",
        "    \"Inhaled bronchodilators(e.g.,salbutamol),inhaled corticosteroid avoids triggers\"\n",
        "))\n",
        "conn.commit()\n",
        "print(\"Inserted successfully\")"
      ],
      "metadata": {
        "id": "qLzUfSoU9l-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cursor = conn.execute(\"SELECT * FROM disease\")\n",
        "for row in cursor:\n",
        "    print(row)"
      ],
      "metadata": {
        "id": "oJ129Dx6Aeyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model = \"meta-llama/Llama-3.1-8B-Instruct\""
      ],
      "metadata": {
        "id": "wZYv2witBXsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ],
      "metadata": {
        "id": "mIaMTfbwDuJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_disease_info(disease_name):\n",
        "  conn = sqlite3.connect('pharmacy.db')\n",
        "  cursor = conn.execute(\"\"\"\n",
        "  SELECT name, symptoms, treatment\n",
        "  FROM disease\n",
        "  WHERE name LIKE ?\n",
        "  \"\"\",(f\"%{disease_name}%\",))\n",
        "  row = cursor.fetchone()\n",
        "  if row:\n",
        "    return{\n",
        "        \"name\": row[0],\n",
        "        \"symptoms\":row[1],\n",
        "        \"treatment\":row[2]\n",
        "    }\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "LYFRm96vIbWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "PP75DcDjOAoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig"
      ],
      "metadata": {
        "id": "8sAKuKMfW3qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "print(\"Using 4-bit quantization\")"
      ],
      "metadata": {
        "id": "fMRoGPtROliy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "pOSALbhMdLDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(Model,trust_remote_code = True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    Model,quantization_config = quant_config,device_map=\"auto\",\n",
        "    torch_dtype = torch.float16,trust_remote_code = True)"
      ],
      "metadata": {
        "id": "yN0UlvsjMUdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(message,history):\n",
        "  try:\n",
        "    disease = get_disease_info(message)\n",
        "\n",
        "    if disease:\n",
        "      system_context = (\n",
        "          f\"You are a medical assistant. Here is information from the database:\\n\\n\"\n",
        "          f\"Disease: {disease['name']}\\n\"\n",
        "          f\"Symptoms: {disease['symptoms']}\\n\"\n",
        "          f\"Treatment: {disease['treatment']}\\n\\n\"\n",
        "          f\"Answer the user's question based on the information provided.\"\n",
        "          )\n",
        "    else:\n",
        "      system_context = (\n",
        "          \"You are a helpful medical assistant. Answer questions about health and diseases.\\n\\n \"\n",
        "      )\n",
        "    conversation = system_context\n",
        "\n",
        "    messages = [{\"role\":\"system\",\"content\":system_context}]\n",
        "    recent_history=history[-5:] if len(history) > 5 else history\n",
        "    for user_msg,assistant_msg in recent_history:\n",
        "      messages.append({\"role\":\"user\",\"content\":user_msg})\n",
        "      messages.append({\"role\":\"assistant\",\"content\":assistant_msg})\n",
        "\n",
        "    messages.append({\"role\":\"user\",\"content\":message})\n",
        "    inputs = tokenizer.apply_chat_template(messages,\n",
        "                                           return_tensors = \"pt\",truncation = True,\n",
        "                                           padding= True,add_generation_prompt=True,\n",
        "                                           return_dict=True).to(\"cuda\")\n",
        "\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    print(f\"Generating response.....\")\n",
        "\n",
        "    streamer = TextIteratorStreamer(tokenizer,timeout=None,skip_prompt=True,skip_special_tokens=True)\n",
        "\n",
        "    generation_kwarg= dict(\n",
        "        **inputs,\n",
        "        streamer = streamer,\n",
        "        max_new_tokens =1024,\n",
        "        temperature = 0.7,\n",
        "        do_sample = True,\n",
        "        pad_token_id = tokenizer.eos_token_id,\n",
        "        eos_token_id = tokenizer.eos_token_id,\n",
        "        repetition_penalty = 1.1\n",
        "\n",
        "   )\n",
        "    thread = Thread(target=model.generate,kwargs=generation_kwarg)\n",
        "    thread.start()\n",
        "    partial_message = \"\"\n",
        "    for new_token in streamer:\n",
        "        if new_token:\n",
        "          partial_message += new_token\n",
        "          yield partial_message\n",
        "  except Exception as e:\n",
        "    error_msg=f\"An error occurred: {str(e)}\"\n",
        "    print(error_msg)\n",
        "    return f\"Error details for debugging:{str(e)}\"\n"
      ],
      "metadata": {
        "id": "pR6X0O0xbN8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextIteratorStreamer\n",
        "from threading import Thread"
      ],
      "metadata": {
        "id": "EjFVej70Q7pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.ChatInterface(\n",
        "    chatbot_response,\n",
        "    title = \"Medical Assistant\",\n",
        "    description = \"Ask about diseases,symptoms,or treatments.\",\n",
        "    examples=[\n",
        "        \"What causes asthma?\",\n",
        "        \"Tell me about malaria symptoms\"\n",
        "    ],\n",
        "    concurrency_limit=5\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"Launching the demo...\")\n",
        "  demo.launch(auth=(\"pharm\",\"doctor\"),inbrowser = True,share= True)"
      ],
      "metadata": {
        "id": "ji8CN2Oak8pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CIeH95IHtB-9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}